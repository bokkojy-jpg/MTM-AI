import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from PIL import Image

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ©
st.set_page_config(page_title="MOATASEM AI", page_icon="ğŸ¤–", layout="wide")

# Ø¥Ø®ÙØ§Ø¡ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù„ÙˆÙŠØ© ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø´ÙƒÙ„
st.markdown("""
    <style>
    .main { background-color: #0e1117; }
    div.stButton > button:first-child { background-color: #007bff; color: white; border-radius: 10px; }
    .stTextInput > div > div > input { background-color: #161b22; color: white; border-radius: 10px; }
    footer {visibility: hidden;}
    .developer-footer {
        position: fixed;
        bottom: 10px;
        left: 10px;
        font-family: sans-serif;
        color: #555;
        font-size: 12px;
    }
    </style>
    """, unsafe_allow_html=True)

# Ø±Ø¨Ø· Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
API_KEY = "AIzaSyBNHHn5ss_b9hce3YwqORi-KCOIifr90lo"
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
with st.sidebar:
    st.title("ğŸ¤– MOATASEM AI")
    st.info("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù‡Ù†Ø§ ÙˆØ§Ø¨Ø¯Ø£ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©")
    uploaded_files = st.file_uploader("Ø§Ø¯Ø¹Ù… PDF Ø£Ùˆ ØµÙˆØ±", type=["pdf", "jpg", "jpeg", "png"], accept_multiple_files=True)
    st.markdown("---")
    st.markdown('<div class="developer-footer">Developed by: MOATASEM AI</div>', unsafe_allow_html=True)

st.title("ğŸ’¬ ØºØ±ÙØ© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø°ÙƒÙŠØ©")

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ
context_text = ""
images = []

if uploaded_files:
    for file in uploaded_files:
        if file.type == "application/pdf":
            reader = PdfReader(file)
            context_text += "".join([p.extract_text() for p in reader.pages])
        else:
            images.append(Image.open(file))
    st.success(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(uploaded_files)} Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­!")

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ø®ØµØµ Ø¹Ù† Ø§Ù„Ù…Ø·ÙˆØ±
        if any(word in prompt.lower() for word in ["Ù…Ù† ØµÙ†Ø¹Ùƒ", "Ù…Ù† Ø·ÙˆØ±Ùƒ", "who made you"]):
            response_text = "Ø£Ù†Ø§ Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ·ÙˆØ±ØŒ ØªÙ… Ø¨Ø±Ù…Ø¬ØªÙŠ ÙˆØªØ·ÙˆÙŠØ±ÙŠ Ø¨ÙˆØ§Ø³Ø·Ø© **Ø§Ù„Ù…Ø¹ØªØµÙ… Ù†Ø¨ÙŠÙ„ Ø§Ù„Ù…Ù„ÙŠÙƒÙŠ**."
        else:
            # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ØµÙˆØ± ÙÙŠ Ø§Ù„Ø±Ø¯
            inputs = [f"Context: {context_text[:3000]}\n\nUser Question: {prompt}"]
            if images:
                inputs.extend(images)
            
            response = model.generate_content(inputs)
            response_text = response.text
            
        st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})
