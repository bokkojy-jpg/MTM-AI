import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from PIL import Image

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© (MOATASEM AI)
st.set_page_config(page_title="MOATASEM AI", page_icon="ğŸ¤–", layout="centered")

# ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ­Ø°Ù Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
st.markdown("""
    <style>
    .main { background-color: #0e1117; }
    footer {visibility: hidden;}
    .developer-footer {
        position: fixed;
        bottom: 10px;
        right: 15px;
        color: #666;
        font-size: 12px;
        font-family: sans-serif;
        z-index: 100;
    }
    </style>
    <div class="developer-footer">Developed by: MOATASEM AI</div>
    """, unsafe_allow_html=True)

# Ø±Ø¨Ø· Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ - ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ù…ÙØªØ§Ø­
# Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø± Ø§Ù„Ø®Ø·Ø£ØŒ Ø³ØªØ­ØªØ§Ø¬ Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ Ø¬Ø¯ÙŠØ¯ Ù…Ù† aistudio.google.com
API_KEY = "gen-lang-client-0933546265" 
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

with st.sidebar:
    st.title("ğŸ¤– MOATASEM AI")
    st.write("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ (PDF Ø£Ùˆ ØµÙˆØ±) ÙˆØ§Ø¨Ø¯Ø£ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©")
    uploaded_files = st.file_uploader("Ø§Ø®ØªØ± Ø§Ù„Ù…Ù„ÙØ§Øª", type=["pdf", "jpg", "jpeg", "png"], accept_multiple_files=True)

st.title("ğŸ’¬ ØºØ±ÙØ© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©")

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
context_text = ""
images = []
if uploaded_files:
    for file in uploaded_files:
        if file.type == "application/pdf":
            try:
                reader = PdfReader(file)
                for page in reader.pages:
                    context_text += page.extract_text()
            except: st.error(f"ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù: {file.name}")
        else:
            images.append(Image.open(file))
    if uploaded_files: st.success("ØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­!")

# Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ø¯Ø±Ø¯Ø´Ø©
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ MOATASEM AI..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # Ø§Ù„Ø±Ø¯ Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„Ù…Ø·ÙˆØ±
        if any(word in prompt.lower() for word in ["Ù…Ù† ØµÙ†Ø¹Ùƒ", "Ù…Ù† Ø·ÙˆØ±Ùƒ", "who made you"]):
            res = "Ø£Ù†Ø§ Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØªÙ… ØªØ·ÙˆÙŠØ±ÙŠ ÙˆØ¨Ø±Ù…Ø¬ØªÙŠ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø·ÙˆØ± Ø§Ù„Ù…Ø¨Ø¯Ø¹ **Ù…Ø¹ØªØµÙ… Ù†Ø¨ÙŠÙ„ Ø§Ù„Ù…Ù„ÙŠÙƒÙŠ**."
        else:
            try:
                # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
                content_list = []
                if context_text:
                    content_list.append(f"Ù‡Ø°Ø§ Ù†Øµ Ù…Ù† Ù…Ù„ÙØ§Øª Ù…Ø±ÙÙˆØ¹Ø© Ù„Ù„Ø§Ø³ØªØ¹Ø§Ù†Ø© Ø¨Ù‡Ø§: {context_text[:4000]}")
                content_list.append(prompt)
                if images:
                    content_list.extend(images)
                
                response = model.generate_content(content_list)
                res = response.text
            except Exception as e:
                res = "Ø¹Ø°Ø±Ø§Ù‹ØŒ ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø¶ØºØ·Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¹Ø¯ Ù„Ø­Ø¸Ø§Øª."
        
        st.markdown(res)
        st.session_state.messages.append({"role": "assistant", "content": res})
