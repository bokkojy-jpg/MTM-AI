    import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
from PIL import Image
import io

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="MOATASEM AI", page_icon="ğŸ§ ", layout="wide")

# --- 2. Ø§Ù„ØªØµÙ…ÙŠÙ… CSS ---
st.markdown("""
    <style>
    .stApp { background: #0e1117; }
    footer {visibility: hidden;}
    .developer-footer {
        position: fixed; bottom: 10px; right: 15px;
        color: #666; font-size: 12px;
    }
    </style>
    <div class="developer-footer">Developed by: MOATASEM AI</div>
    """, unsafe_allow_html=True)

# --- 3. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API (Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„ØµØ­ÙŠØ­) ---
API_KEY = "AIzaSyCC69LDLdON1hSCQ1QIr7zRFvTLouCFV-s" 
genai.configure(api_key=API_KEY)

# Ø§Ù„Ø­Ù„ Ù‡Ù†Ø§: Ø¬Ø±Ø¨Ù†Ø§ 'gemini-pro' Ù„Ø£Ù†Ù‡ Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹ ÙˆÙ…Ø¬Ø§Ù†ÙŠ ØªÙ…Ø§Ù…Ø§Ù‹
try:
    model = genai.GenerativeModel('gemini-pro')
except:
    model = genai.GenerativeModel('gemini-1.5-flash-latest')

# --- 4. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø© ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "context" not in st.session_state:
    st.session_state.context = ""

# --- 5. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
with st.sidebar:
    st.title("ğŸ¤– MOATASEM AI")
    uploaded_files = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ", type=["pdf", "jpg", "png"], accept_multiple_files=True)
    if st.button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ---
if uploaded_files:
    text_content = ""
    for file in uploaded_files:
        if file.type == "application/pdf":
            reader = PdfReader(file)
            for page in reader.pages:
                text_content += page.extract_text() + "\n"
    st.session_state.context = text_content
    st.sidebar.success("âœ… ØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

# --- 7. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„Ø¯Ø±Ø¯Ø´Ø© ---
st.markdown("<h2 style='text-align: center;'>ğŸ§  Ù…Ø­Ø±Ùƒ Ù…Ø¹ØªØµÙ… Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ</h2>", unsafe_allow_html=True)

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        if any(w in prompt.lower() for w in ["Ù…Ù† ØµÙ†Ø¹Ùƒ", "Ù…Ù† Ø·ÙˆØ±Ùƒ", "who made you"]):
            response_text = "ØªÙ… ØªØ·ÙˆÙŠØ±ÙŠ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø¨Ø¯Ø¹ **Ù…Ø¹ØªØµÙ… Ù†Ø¨ÙŠÙ„ Ø§Ù„Ù…Ù„ÙŠÙƒÙŠ**."
        else:
            try:
                # Ø¯Ù…Ø¬ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù„ÙØ§Øª
                full_input = f"Context: {st.session_state.context[:5000]}\nQuestion: {prompt}"
                response = model.generate_content(full_input)
                response_text = response.text
            except Exception as e:
                response_text = "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù„Ù…Ø­Ø±Ùƒ ÙŠØ­ØªØ§Ø¬ Ù„Ù„ØªØ­Ø¯ÙŠØ«. ØªØ£ÙƒØ¯ Ù…Ù† Ø§ØªØµØ§Ù„ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙˆØ­Ø§ÙˆÙ„ Ù…Ø¬Ø¯Ø¯Ø§Ù‹."

        st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})
